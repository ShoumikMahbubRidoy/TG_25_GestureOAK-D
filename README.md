# TG_25_GestureOAK-D

Real-time **hand detection** and **swipe gesture recognition** system built for the [Luxonis OAK-D-PRO](https://shop.luxonis.com/products/oak-d-pro).  
Optimized for **80â€“160 cm operating distance**, with IR-based robustness and UDP integration.

---

## ğŸ“Œ What is done?
- **Hand Detection** using stereo IR cameras + depth filtering.  
- **Swipe Detection** (left-to-right) with distance, velocity, and debounce logic.  
- **UDP Messaging** on confirmed swipe to `192.168.10.10:6001`.  
- **Performance Optimizations**: non-blocking queues, OpenCV runtime tuning.  
- **Gesture Hooks (WIP)**: placeholders for finger-count and multi-hand classification.

---

## ğŸ¤” Why is this done?
- Original depthai tracker struggled at **mid-range distances**.  
- Needed **stable swipe events** to control robots.  
- IR-based pipeline makes it usable in **dark or mixed-light environments**.  

---

## âš™ï¸ How is this done?
- **DepthAI Pipeline**: palm NN â†’ postproc â†’ landmark NN â†’ IR-enhanced frames.  
- **Swipe Detector**: buffered trajectory â†’ min distance + velocity check.  
- **Depth Filtering**: keeps stable hands in **300â€“2000 mm range**.  
- **IR Enhancement**: CLAHE + bilateral filter for edge-preserving contrast.  

---

## ğŸ“¦ Requirements
- Python **3.10+**  
- DepthAI SDK (`depthai`)  
- OpenCV â‰¥ 4.8  
- NumPy  
- imutils  
- PyYAML (optional config)

See [`requirements.txt`](requirements.txt) for full list.

---

## ğŸ› ï¸ Installation

**Clone:**
```bash
git clone https://github.com/ShoumikMahbubRidoy/TG_25_GestureOAK-D.git
cd TG_25_GestureOAK-D
```

**Setup venv:**
```bash
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\Activate.ps1  # Windows
```

**Install deps:**
```bash
pip install -r requirements.txt
```

## ğŸ“‚ Directory Tree
```css
TG_25_GestureOAK-D/
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ palm_detection_sh4.blob
â”‚   â”œâ”€â”€ hand_landmark_lite_sh4.blob
â”‚   â””â”€â”€ PDPostProcessing_top2_sh1.blob
â”œâ”€â”€ src/gesture_oak/
â”‚   â”œâ”€â”€ apps/
â”‚   â”‚   â””â”€â”€ hand_tracking_app.py
â”‚   â”œâ”€â”€ detection/
â”‚   â”‚   â”œâ”€â”€ hand_detector.py
â”‚   â”‚   â””â”€â”€ swipe_detector.py
â”‚   â”œâ”€â”€ logic/
â”‚   â”‚   â””â”€â”€ gesture_classifier.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ mediapipe_utils.py
â”‚       â”œâ”€â”€ FPS.py
â”‚       â””â”€â”€ template_manager_script_solo.py
â””â”€â”€ docs/
    â”œâ”€â”€ application-architecture.md
    â”œâ”€â”€ implementation-tasks.md
    â””â”€â”€ troubleshooting.md

```

## ğŸš€ How to Run
```bash
uv run python main.py
```

Menu:
```markdown
1. Test camera connection
2. Run hand tracking app
3. Run swipe detection app
4. Run motion-based swipe detection
5. Exit
```

## Workflow
- Choose 2/3 for hand tracking.
- Place hand 80â€“160 cm from OAK-D camera.
- Perform a left-to-right swipe.
- Observe console logs and UDP packet output.

## ğŸ“ˆ Known Issues
- Left hand less reliable beyond ~100 cm.
- Background objects (cloth, hair, ear, etc.) may cause false positives.
- FPS reporting bug: unrealistic values (>200k fps) are artifacts.

## ğŸ—ºï¸ Roadmap
- Finger-count gestures (1â€“5, peace, fist).
- Multi-hand support.
- Custom dataset training for robustness.
- Integrate MediaPipe HandLandmarker.
- Fix FPS counter (target 25â€“60 fps realistic).

## ğŸ“œ License
**MIT**
```yaml

---

ğŸ‘‰ Now the README includes **everything in one file**:  
- What / Why / How  
- Requirements  
- Install  
- Directory Tree  
- Run + Menu + Workflow  
- Issues  
- Roadmap  

No parts are floating outside anymore.  

Do you also want me to create the **new `requirements.txt`** (cleaned, with only exact deps you need) right now?
```